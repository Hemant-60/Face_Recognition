{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier('[DIR_WITH_HAARCASCADE_CLASSIFIERS]/haarcascades/haarcascade_eye.xml')\n",
    "face_cascade = cv2.CascadeClassifier('[DIR_WITH_HAARCASCADE_CLASSIFIERS]/haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "recognizer =cv2.face.LBPHFaceRecognizer_create() #cv2.face.createLBPHFaceRecognizer()#\n",
    "smile_cascade = cv2.CascadeClassifier('[DIR_WITH_HAARCASCADE_CLASSIFIERS]/haarcascades/haarcascade_smile.xml')\n",
    "\n",
    "\n",
    "recognizer.read(\"trainner.yml\")\n",
    "labels={\"person_name\": 1}\n",
    "\n",
    "with open(\"labels.pickle\", 'rb') as f:\n",
    "    ogLabels = pickle.load(f)\n",
    "    labels = {v:k for k,v in ogLabels.items()}\n",
    "\n",
    "cap =cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray , scaleFactor=1.5  ,minNeighbors = 5)\n",
    "    for(x, y, w, h) in faces:\n",
    "        #print(x,y,w,h)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        id_ , conf = recognizer.predict(roi_gray)\n",
    "        #print(conf)\n",
    "        #print(id_)\n",
    "        if (conf >= 4) and (conf <= 85):\n",
    "            #print(id_)\n",
    "            #print(labels[id_])\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = labels[id_]\n",
    "            color=(255,255,255)\n",
    "            stroke= 2\n",
    "            cv2.putText(frame,name,(x,y), font ,1 ,color ,stroke ,cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        img_item = \"7.png\"\n",
    "        cv2.imwrite(img_item,roi_gray)\n",
    "        color = (72,120 ,0)\n",
    "        stroke = 4\n",
    "        cv2.rectangle(frame, (x,y) , (x+w, y+h),color , stroke) \n",
    "        subitems = smile_cascade.detectMultiScale(roi_gray)\n",
    "        for(ex,ey,ew,eh) in subitems:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew , ey+eh) , (8,255,8) ,2)\n",
    "\n",
    "\n",
    "    cv2.imshow('frame' ,frame)\n",
    "    if cv2.waitKey(20) & 0xFF ==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#roi  region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[array([[ 38,  43,  43, ..., 255, 255, 255],\n",
      "       [ 44,  44,  42, ..., 255, 255, 255],\n",
      "       [ 38,  43,  42, ..., 255, 255, 255],\n",
      "       ...,\n",
      "       [ 57,  47,  49, ..., 233, 234, 234],\n",
      "       [ 47,  49,  53, ..., 233, 233, 233],\n",
      "       [ 44,  57,  64, ..., 233, 233, 233]], dtype=uint8), array([[ 99,  96,  84, ...,  82,  85,  87],\n",
      "       [ 96,  99,  95, ...,  79,  84,  87],\n",
      "       [ 94,  88,  89, ...,  83,  92,  95],\n",
      "       ...,\n",
      "       [220, 220, 220, ..., 253, 252, 252],\n",
      "       [220, 220, 220, ..., 253, 253, 253],\n",
      "       [220, 220, 220, ..., 253, 253, 253]], dtype=uint8), array([[ 22,  20,  19, ...,  13,  13,  13],\n",
      "       [ 22,  20,  19, ...,  13,  13,  12],\n",
      "       [ 22,  20,  19, ...,  12,  12,  12],\n",
      "       ...,\n",
      "       [156, 155, 154, ..., 138, 137, 136],\n",
      "       [156, 155, 154, ..., 142, 140, 142],\n",
      "       [157, 154, 154, ..., 141, 138, 143]], dtype=uint8), array([[174, 176, 175, ..., 157, 156, 155],\n",
      "       [174, 174, 175, ..., 156, 155, 155],\n",
      "       [174, 174, 175, ..., 157, 156, 155],\n",
      "       ...,\n",
      "       [157, 157, 157, ..., 137, 137, 138],\n",
      "       [157, 157, 157, ..., 137, 137, 138],\n",
      "       [156, 157, 157, ..., 135, 136, 138]], dtype=uint8), array([[173, 173, 173, ...,  28,  27,  27],\n",
      "       [174, 174, 173, ...,  28,  28,  27],\n",
      "       [174, 174, 174, ...,  28,  27,  26],\n",
      "       ...,\n",
      "       [157, 157, 158, ...,  30,  29,  28],\n",
      "       [157, 157, 157, ...,  30,  28,  28],\n",
      "       [157, 157, 157, ...,  30,  28,  27]], dtype=uint8), array([[181, 180, 179, ..., 159, 159, 158],\n",
      "       [181, 181, 181, ..., 158, 158, 158],\n",
      "       [180, 181, 181, ..., 158, 158, 157],\n",
      "       ...,\n",
      "       [159, 159, 159, ...,  40,  50,  58],\n",
      "       [159, 159, 158, ...,  41,  48,  53],\n",
      "       [158, 158, 158, ...,  27,  31,  35]], dtype=uint8), array([[166, 161, 153, ..., 161, 161, 161],\n",
      "       [168, 164, 157, ..., 162, 161, 161],\n",
      "       [168, 163, 157, ..., 162, 161, 161],\n",
      "       ...,\n",
      "       [156, 156, 156, ..., 138, 136, 134],\n",
      "       [157, 157, 157, ..., 133, 129, 138],\n",
      "       [158, 158, 158, ..., 128, 131, 139]], dtype=uint8), array([[167, 168, 168, ..., 158, 158, 158],\n",
      "       [166, 165, 166, ..., 158, 157, 158],\n",
      "       [165, 164, 164, ..., 157, 157, 157],\n",
      "       ...,\n",
      "       [151, 151, 151, ..., 140, 141, 142],\n",
      "       [151, 152, 152, ..., 140, 141, 141],\n",
      "       [151, 152, 152, ..., 140, 141, 141]], dtype=uint8), array([[ 24,  22,  19, ...,  10,  10,  10],\n",
      "       [ 25,  24,  21, ...,  10,   9,   8],\n",
      "       [ 27,  26,  22, ...,   9,   8,   7],\n",
      "       ...,\n",
      "       [151, 151, 150, ..., 140, 141, 141],\n",
      "       [153, 152, 151, ..., 139, 139, 139],\n",
      "       [154, 154, 153, ..., 138, 138, 139]], dtype=uint8), array([[ 17,  18,  19, ...,   7,   7,   6],\n",
      "       [ 19,  21,  22, ...,   7,   7,   6],\n",
      "       [ 20,  22,  23, ...,   7,   7,   7],\n",
      "       ...,\n",
      "       [148, 149, 151, ..., 138, 138, 138],\n",
      "       [148, 149, 150, ..., 137, 138, 138],\n",
      "       [147, 148, 150, ..., 137, 137, 138]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "#baseDirectory  = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "imageDirectory = os.path.dirname(\"[DIR_WITH_DIRECTORIES_OF_IMAGES]/images\")\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('[DIR_WITH_HAARCASCADE_CLASSIFIERS]/haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "recognizer =cv2.face.LBPHFaceRecognizer_create() #cv2.face.creaeLBPHFaceRecognizer()#\n",
    "\n",
    "currentId = 0\n",
    "label_ids = {}\n",
    "yLabel = []\n",
    "xTrain = []\n",
    "\n",
    "for root , dirs , files in os.walk(imageDirectory):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path = os.path.join(root,file)\n",
    "            label = os.path.basename(root).replace(\" \",\"-\").lower()\n",
    "            #os.path.dirname(path)  can be written as root\n",
    "            #print(label,path)\n",
    "\n",
    "            if label in label_ids:\n",
    "                pass\n",
    "            else:\n",
    "                label_ids[label] = currentId\n",
    "                currentId+=1\n",
    "            id_=label_ids[label]\n",
    "            #print(label_ids)\n",
    "\n",
    "           # yLabel.append(label)\n",
    "            #xTrain.append(path)\n",
    "            pilImage = Image.open(path).convert(\"L\")\n",
    "            size = (550, 550)\n",
    "            final_image = pilImage.resize(size,Image.ANTIALIAS)\n",
    "            imageArray = np.array(pilImage, \"uint8\")\n",
    "            #print(imageArray)\n",
    "            faces = face_cascade.detectMultiScale(imageArray, scaleFactor=1.5  ,minNeighbors = 5)\n",
    "\n",
    "            #print(id_)\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = imageArray[y:y+h , x:x+h]\n",
    "                xTrain.append(roi)\n",
    "                yLabel.append(id_)\n",
    "\n",
    "print(yLabel)\n",
    "print(xTrain)\n",
    "\n",
    "with open(\"labels.pickle\", 'wb') as f:\n",
    "    pickle.dump(label_ids , f)\n",
    "\n",
    "recognizer.train(xTrain , np.array(yLabel))\n",
    "recognizer.save(\"trainner.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
